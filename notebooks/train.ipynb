{"cells":[{"cell_type":"markdown","metadata":{"id":"U9P9PmZMoK9Y"},"source":["# 概要\n","歌詞からアーティスト名を予測する分類モデルを学習させるコードです。\n","\n","テキストを文字単位で分割して入力する「CharacterCNN」を採用しています。\n","\n","論文→https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf"]},{"cell_type":"markdown","metadata":{"id":"rpaNulaWo9Ui"},"source":["# ライブラリのインポート"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1693528551132,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"7OqkgxvoXDYk"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import japanize_matplotlib\n","from tqdm import tqdm\n","import copy\n","import os\n","import json\n","import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split, GroupKFold"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1693526734829,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"4xWTUZ_8pCJY"},"outputs":[],"source":["# 保存先のパス\n","PATH = './'"]},{"cell_type":"markdown","metadata":{"id":"LWcqfDjZpEq9"},"source":["# 歌詞データの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":783,"status":"ok","timestamp":1693528220475,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"uwqsUzxX6P0-","outputId":"70478c0e-e25d-48d8-c909-0dc337a0c895"},"outputs":[],"source":["# 歌詞CSVの読み込み\n","df = pd.read_csv(PATH+'data/lyric_block.csv')\n","print(df.artist.unique())"]},{"cell_type":"markdown","metadata":{"id":"w0TAdF5VDIkR"},"source":["# アーティストを選択\n","- `artists`に分類先のアーティスト名を格納する。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"executionInfo":{"elapsed":1127,"status":"ok","timestamp":1693529460842,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"wvAUxAAR6XV9","outputId":"85b7e425-aba1-4615-d58c-d59449b5d050"},"outputs":[],"source":["# 分類対象のアーティストを選択\n","artists = ['あいみょん', 'スピッツ', '星野源', 'YOASOBI']\n","df_sub = df[df['artist'].isin(artists)]\n","\n","# アーティスト名を整数化(idとは別。ラベル用)\n","artist_to_label = {artist:i for i,artist in enumerate(artists)}\n","\n","# 各アーティストのデータ数を棒グラフで可視化\n","plt.figure(figsize=(10,3))\n","df_sub['artist'].value_counts().plot(kind='bar')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XzByzyKNDRvh"},"source":["# 前処理\n","- 各文字をUnicodeに変換\n","- 特徴量をXへ、ラベルをyへ格納"]},{"cell_type":"code","execution_count":160,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693529462721,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"y_fld_QFX0TH"},"outputs":[],"source":["def encode(txt, max_length=200):\n","    \"\"\"\n","    歌詞の1文字1文字をUnicodeに変換する関数\n","\n","    Parameters:\n","        txt (iterable of str): Text or iterable of texts to be encoded.\n","        max_length (int, optional): Maximum length of encoded sequence. Default is 200.\n","\n","    Returns:\n","        numpy.ndarray: Encoded sequence(s) as a NumPy array.\n","\n","    Notes:\n","        - Each character in the input text(s) is converted to its corresponding Unicode code point.\n","        - The resulting encoded sequence(s) are padded or truncated to match the specified maximum length.\n","        - If the input text(s) are shorter than the maximum length, the remaining elements are filled with zeros.\n","\n","    Example:\n","        txt = [\"Hello, world!\"]\n","        encoded_txt = encode(txt, max_length=10)\n","        print(encoded_txt)\n","        # Output: [[ 72 101 108 108 111  44  32 119 111 114]]\n","    \"\"\"\n","    txt_list = []\n","    for l in txt:\n","        txt_line = [ord(x) for x in str(l).strip()]\n","        txt_line = txt_line[:max_length]\n","        txt_len = len(txt_line)\n","        if txt_len < max_length:\n","            txt_line += ([0] * (max_length - txt_len))\n","        txt_list.append((txt_line))\n","    return np.array(txt_list)"]},{"cell_type":"code","execution_count":161,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1680,"status":"ok","timestamp":1693529465458,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"UydokIB9Yjst","outputId":"5fc338f8-8d3a-4475-f853-94eea88f74c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(54922, 200) (54922,)\n"]}],"source":["# 説明変数X\n","X = encode(df_sub['block'])\n","# 目的変数y\n","y = df_sub['artist'].map(artist_to_label).values\n","print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"iZ9qEMDrDblY"},"source":["# ネットワークの定義"]},{"cell_type":"code","execution_count":162,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693529466750,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"RNhL2V6Ym-1B"},"outputs":[],"source":["class CharacterCNN(nn.Module):\n","    def __init__(self, num_classes ,embed_size=128, max_length=200, filter_sizes=(2, 3, 4, 5), filter_num=64):\n","        super().__init__()\n","        self.params = {'num_classes': num_classes ,'embed_size':embed_size, 'max_length':max_length, 'filter_sizes':filter_sizes, 'filter_num':filter_num}\n","        self.embed_size = embed_size\n","        self.max_length = max_length\n","        self.filter_sizes = filter_sizes\n","        self.filter_num = filter_num\n","\n","        self.embedding = nn.Embedding(0xffff, embed_size)\n","        self.conv_layers = nn.ModuleList([\n","            nn.Conv1d(embed_size, filter_num, filter_size) for filter_size in filter_sizes\n","        ])\n","        self.fc1 = nn.Linear(filter_num * len(filter_sizes), 64)\n","        self.batch_norm = nn.BatchNorm1d(64)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x).transpose(1,2)\n","\n","        conv_outputs = []\n","        for conv_layer in self.conv_layers:\n","            conv_output = F.relu(conv_layer(embedded))\n","            pooled = F.max_pool1d(conv_output, conv_output.size(2)).squeeze(2)\n","            conv_outputs.append(pooled)\n","\n","        convs_merged = torch.cat(conv_outputs, dim=1)\n","        fc1_output = F.relu(self.fc1(convs_merged))\n","        bn_output = self.batch_norm(fc1_output)\n","        do_output = self.dropout(bn_output)\n","        fc2_output = self.fc2(do_output)\n","        return fc2_output"]},{"cell_type":"markdown","metadata":{"id":"nRzz8a5K_DCV"},"source":["# 学習\n","- `n_epochs`, `batch_size`, `learning_rate`, `optimizer`などを設定する。\n","- 同じ歌の歌詞が、学習用データと評価用データへ混在しないようにGroupKFold。（1曲の中で同じ歌詞が繰り返し登場するため）\n","- 各foldのBestモデルを保存する。"]},{"cell_type":"code","execution_count":163,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1693529474773,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"85Msf1Fq_B1e","outputId":"32ace794-eb56-410a-858f-d77964943380"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["n_epochs = 10          # エポック数\n","batch_size = 256       # バッチサイズ\n","learning_rate = 0.001  # 学習率\n","n_splits = 5           # GroupKFoldの分割数\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","gkf = GroupKFold(n_splits)  # GroupKfold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387966,"status":"ok","timestamp":1693529869883,"user":{"displayName":"松田拓巳","userId":"04885087158132440554"},"user_tz":-540},"id":"h-o47kqs-3bh","outputId":"3c0849e7-ab26-46fa-a340-415fc0051c95"},"outputs":[],"source":["now = datetime.datetime.now().strftime('%Y%m%d%H%M%S%f')\n","for fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=df_sub['title'])):\n","    # 学習データと評価用データに分割\n","    print(f'-----Fold{fold+1}/{n_splits}-----')\n","    X_tr, X_va = X[tr_idx], X[va_idx]\n","    y_tr, y_va = y[tr_idx], y[va_idx]\n","    n_iter = len(y_tr)//batch_size\n","\n","    bst_model = None\n","    bst_score = np.inf\n","    model = CharacterCNN(num_classes=len(artists), embed_size=128, filter_sizes=(2,3,4,5), filter_num=64).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # 学習\n","    for epoch in range(n_epochs):\n","        model.train()\n","        total_loss = 0.0\n","        total_correct = 0\n","        random_idx = np.random.permutation(len(y_tr))\n","        for i in range(n_iter):\n","            X_batch = torch.from_numpy(X_tr[random_idx[batch_size*i:batch_size*(i+1)]]).to(device)\n","            y_batch = torch.from_numpy(y_tr[random_idx[batch_size*i:batch_size*(i+1)]]).to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            _, predicted = outputs.max(dim=1)\n","            total_correct += (predicted == y_batch).sum().item()\n","\n","        train_loss = total_loss / n_iter\n","        train_acc = total_correct / (batch_size*n_iter)\n","\n","        # 評価\n","        model.eval()\n","        with torch.no_grad():\n","            outputs = model(torch.from_numpy(X_va).to(device))\n","            loss = criterion(outputs, torch.from_numpy(y_va).to(device))\n","            valid_loss = loss.item()\n","            _, predicted = outputs.max(dim=1)\n","            valid_acc = (predicted == torch.from_numpy(y_va).to(device)).sum().item() / len(y_va)\n","        print(f'Epoch[{epoch+1}/{n_epochs}], TrainLoss: {train_loss:.4f}, ValidLoss: {valid_loss:.4f}, TrainAcc: {train_acc*100:.4f}%, ValidAcc: {valid_acc*100:.4f}%')\n","\n","        # best更新処理\n","        if valid_loss < bst_score:\n","            bst_model = copy.deepcopy(model)\n","            bst_score = valid_loss\n","            bst_epoch = epoch + 1\n","\n","    # ベストモデルを保存\n","    os.makedirs(PATH+f'models/model_{now}', exist_ok=True)\n","    torch.save(bst_model.cpu(), PATH+f'models/model_{now}/model_fold{fold+1}.pth')\n","\n","    # モデルの情報をjsonに記録\n","    if fold == 0:\n","        data = dict()\n","        data['ClassNames'] = artists\n","\n","    bst_info = dict()\n","    bst_info['TrainSize'] = len(y_tr)\n","    bst_info['ValidSize'] = len(y_va)\n","    bst_info['Params'] = model.params\n","    bst_info['BatchSize'] = batch_size\n","    bst_info['LearningRate'] = learning_rate\n","    bst_info['Optimizer'] = str(type(optimizer))\n","    bst_info['Epoch'] = bst_epoch\n","    bst_info['TrainLoss'] = train_loss\n","    bst_info['ValidLoss'] = valid_loss\n","    bst_info['TrainAcc'] = train_acc * 100\n","    bst_info['ValidAcc'] = valid_acc * 100\n","\n","    data[f'Fold{fold+1}'] = bst_info\n","\n","with open(PATH + f'models/model_{now}/info.json', 'w') as f:\n","    json.dump(data, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Bi0fsylPuUs"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPjwq7Vu85292XE0lQboy8I","gpuType":"T4","mount_file_id":"17tWRBIVJ8hhKS0OPUQfQ2S872ty_E98C","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
